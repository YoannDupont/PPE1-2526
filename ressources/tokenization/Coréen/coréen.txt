웹크롤러(webcrawler)는조직적,자동화된방법으로월드와이드웹을탐색하는컴퓨터프로그램이다.

웹크롤러가하는작업을'웹크롤링'(webcrawling)혹은'스파이더링'(spidering)이라부른다.검색엔진과같은여러사이트에서는데이터의최신상태유지를위해웹크롤링한다.웹크롤러는대체로방문한사이트의모든페이지의복사본을생성하는데사용되며,검색엔진은이렇게생성된페이지를보다빠른검색을위해인덱싱한다.또한크롤러는링크체크나HTML코드검증과같은웹사이트의자동유지관리작업을위해사용되기도하며,자동이메일수집과같은웹페이지의특정형태의정보를수집하는데도사용된다.

웹크롤러는봇이나소프트웨어에이전트의한형태이다.웹크롤러는대개시드(seeds)라고불리는URL리스트에서부터시작하는데,페이지의모든하이퍼링크를인식하여URL리스트를갱신한다.갱신된URL리스트는재귀적으로다시방문한다.
